# 1.1 머신러닝이란??

## 머신러닝의 정의

***"머신러닝은 명시적이 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야다."*** - **Arthur Samuel, 1959**

***"어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 때 경험 E로 인해 성능이 향상됐다면, 이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한 것이다."*** - **Tom Mitchell, 1997**



# 1.2 왜 머신러닝을 사용하는가?

- 전통적인 프로그래밍 기법에서는 규칙이 점점 길고 복잡해져 유지보수가 매우 힘들다. 반면, 머신러닝은 자동으로 학습한다. 따라서, 프로그램이 짧아지고 유지보수가 쉽다.
- 전통적인 방식으로는 너무 복잡한 프로그램이 나오거나, 아예 불가능하여 알려진 알고리즘이 없는 분야가 있다. EX) 음성 인식
- 반대로 머신러닝을 통해 예상치 못한 연관 관계나 새로운 추세가 발견되기도 한다. 우리는 이를 통해 문제를 더욱 잘 이해할 수 있게된다. 이를 **데이터 마이닝**이라고 한다.

정리하자면 다음의 상황에서 머신러닝이 뛰어나다.

1. 기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제
2. 전통적인 방식으로는 해결 할 수 없는 복잡한 문제
3. 유동적인 환경
4. 복잡한 문제와 대량의 데이터에서 통찰을 얻을 때



# 1.3 애플리케이션 사례

1. 생산 라인에서 제품 이미지를 분석해 자동으로 분류하기 - 이미지 분류/CNN
2. 뇌를 스캔하여 종양 진단하기 - 시맨틱 분할/CNN
3. 자동으로 뉴스 기사를 분류하기 - 자연어 처리 및 텍스트 분류/RNN,CNN,Transformer
4. 부정적인 댓글을 자동으로 구분하기 - 자연어 처리 및 텍스트분류
5. 긴 문서를 자동으로 요약하기- 자연어 처리 (텍스트 요약)
6. 챗봇이나 개인 비서 만들기 - 자연어 이해, 질문-대답 모듈
7. 성능 지표 기반으로 수익 예측하기 - 회귀/Linear Regression, SVM, Random Forest, ANN, RNN, CNN, Transformer
8. 음성 명령 어플 만들기 - 음성 인식/RNN,CNN,Transformer
9. 신용 카드 부정거래 감지 - 이상치 탐지
10. 구매 이력 기반 군집화를 통한 마케팅 - 군집(Clustering)
11. 복잡한 데이터 셋을 그래프로 표현하기 - 데이터 시각화/차원 축소(Dimensionality reduction)
12. 구매 이력을 기반으로 상품 추천 - 추천 시스템/ANN
13. 지능형 게임 봇 - 강화학습



# 1.4 머신러닝 시스템의 종류

넓은 범주에서 분류하면 다음과 같다.

- 사람의 감독하에 훈련하는가?  - **지도학습 VS 비지도학습**
- 실시간으로 점진적인 학습을 하는가? -  **온라인 학습 VS 배치 학습**

- 예측 모델을 만드는가? 알고 있는 데이터 포인트와 비교하는가? - **모델 기반 학습 VS 사례 기반 학습 **

## 1.4.1 지도 학습과 비지도 학습

머신러닝 시스템을 **'학습하는 동안의 감독 형태나 정보량'**에 따라 분류할 수 있다. - **지도 학습, 비지도 학습. 준지도 학습, 강화 학습**

### 지도 학습(Supervised Learning)

- **지도 학습은** **훈련 데이터**에 **레이블**(Label)이 포함된다.

- **분류**(Classification)와 **회귀**(Regression)가 대표적인 지도 학습 작업이다.

- **회귀**는 **특성**(예측변수)를 사용해 **타겟**수치를 예측하는 것이다.

- 일부 **회귀** 알고리즘은 **분류**에 사용할 수도 있다. 또한 일부 **분류** 알고리즘도 **회귀**에 사용할 수도 있다.

- 다음은 가장 중요한 **지도 학습** 알고리즘이다.

  1. K-Nearest Neighbors (KNN, K-최근접 이웃)

  2. Linear Regression (선형 회귀)

  3. Logistic Regression (로지스틱 회귀)

  4. Support Vector Machine (SVM, 서포트 벡터 머신)

  5. Decision Tree ( 의사결정트리)

  6. Random Forest (랜덤 포레스트)

  7. Artificial Neural Networks (ANN or NN, 인공신경망)

### 비지도 학습(Unsupervised Learning)

- **비지도 학습**은 **훈련 데이터**에 **레이블**이 없다.
- 다음은 가장 중요한 **비지도 학습** 알고리즘이다.
  - 군집(Clustering)
    1. K-means (K-평균)
    2. DBSCAN (**D**ensity-**b**ased **s**patial **c**lustering of **a**pplications with **n**oise)
    3. HCA (계층 군집 분석, **H**ierarchical **C**luster **A**nalysis)
    4. Outlier Detection (이상치 탐지)
    5. Novelty Detection (특이치 탐지)
    6. One-class SVM (원-클래스)
    7. Isolation Forest (아이솔레이션 포레스트)
  - 시각화(Visualization)와 차원 축소(Dimensionally reduction)
    1. PCA (주성분 분석, **P**rincipal **C**omponent **A**nalysis)
    2. 커널(kernel) PCA
    3. LLE (지역적 선형 임베딩, Locally-Linear Embedding)
    4. t-SNE (**t**-**D**istrubuted **S**tochastic **N**eighbor **E**mbedding)
  - 연관 규칙 학습(Association rule learning)
    1. Apriori (어프라이어리)
    2. Eclat (이클렛)
- **HCA** 알고리즘을 이용하면 각 그룹을 더 작은 그룹으로 세분화할 수 있다.
- **시각화** 알고리즘은 대규모의 고차원 데이터를 도식화가 가능한 2D or 3D 표현으로 만들어준다.
- **시각화** 알고리즘은 가능한 한 구조를 그대로 유지하려 하므로 데이터가 어떻게 조직되어 있는지 이해할 수 있고 예상치 못한 패턴을 발견할 수 있다.
- **차원 축소**는  너무 많은 정보를 잃지 않으면서 데이터를 간소화하는 작업이다.
- **차원 축소**를 하는 한 가지 방법은 상관관계가 있는 여러 특성을 하나로 합치는 것이다. 이를 **특성 추출**(Feature Extraction)이라고 한다.
- **이상치 탐지**는 이상한 값을 자동으로 제거할 때 사용된다.
- **이상치 탐지** 알고리즘을 훈련할때는 대부분 정상적인 샘플이 필요하다.
- **특이치 탐지**는 훈련 세트의 모든 샘플과 달라 보이는 새로운 샘플을 탐지하는 것이 목적이다.
- **특이치 탐지** 알고리즘을 학습시키기 위해서는 매우 **"깨끗한"** 훈련 세트가 필요하다.
- **연관 규칙 학습**은 대량의 데이터에서 특성 간의 흥미로운 관계를 찾는 것이 목표이다.

### 준지도 학습 (Semisupervised Learning)

- **준지도 학습**은 일부만 레이블이 있는 데이터를 다룰 수 있다.
- 대부분의 **준지도 학습** 알고리즘은 **지도 학습**과 **비지도 학습**의 조합으로 이루어져 있다.
- 예시로, **DBN**(심층 신뢰 신경망, **D**eep **B**elief **N**etwork)은  **RBM**(제한된 볼츠만 머신, **R**estricted **B**oltzmann **M**achine)이라고 불리는 비지도 학습 알고리즘을 여러 겹 쌓은 것인데 **RBM**이 **비지도 학습**으로 순차적으로 훈련된 다음 전체 시스템이 **지도 학습** 방식으로 세밀하게 조정된다.

### 강화 학습 (Reinforcement Learning)

- **강화 학습**은 매우 다른 종류의 알고리즘이다.
- 

