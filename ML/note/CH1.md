# 1.1 머신러닝이란??

## 머신러닝의 정의

***"머신러닝은 명시적이 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야다."*** - **Arthur Samuel, 1959**

***"어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 때 경험 E로 인해 성능이 향상됐다면, 이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한 것이다."*** - **Tom Mitchell, 1997**



# 1.2 왜 머신러닝을 사용하는가?

- 전통적인 프로그래밍 기법에서는 규칙이 점점 길고 복잡해져 유지보수가 매우 힘들다. 반면, 머신러닝은 자동으로 학습한다. 따라서, 프로그램이 짧아지고 유지보수가 쉽다.
- 전통적인 방식으로는 너무 복잡한 프로그램이 나오거나, 아예 불가능하여 알려진 알고리즘이 없는 분야가 있다. EX) 음성 인식
- 반대로 머신러닝을 통해 예상치 못한 연관 관계나 새로운 추세가 발견되기도 한다. 우리는 이를 통해 문제를 더욱 잘 이해할 수 있게된다. 이를 **데이터 마이닝**이라고 한다.

정리하자면 다음의 상황에서 머신러닝이 뛰어나다.

1. 기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제
2. 전통적인 방식으로는 해결 할 수 없는 복잡한 문제
3. 유동적인 환경
4. 복잡한 문제와 대량의 데이터에서 통찰을 얻을 때



# 1.3 애플리케이션 사례

1. 생산 라인에서 제품 이미지를 분석해 자동으로 분류하기 - 이미지 분류/CNN
2. 뇌를 스캔하여 종양 진단하기 - 시맨틱 분할/CNN
3. 자동으로 뉴스 기사를 분류하기 - 자연어 처리 및 텍스트 분류/RNN,CNN,Transformer
4. 부정적인 댓글을 자동으로 구분하기 - 자연어 처리 및 텍스트분류
5. 긴 문서를 자동으로 요약하기- 자연어 처리 (텍스트 요약)
6. 챗봇이나 개인 비서 만들기 - 자연어 이해, 질문-대답 모듈
7. 성능 지표 기반으로 수익 예측하기 - 회귀/Linear Regression, SVM, Random Forest, ANN, RNN, CNN, Transformer
8. 음성 명령 어플 만들기 - 음성 인식/RNN,CNN,Transformer
9. 신용 카드 부정거래 감지 - 이상치 탐지
10. 구매 이력 기반 군집화를 통한 마케팅 - 군집(Clustering)
11. 복잡한 데이터 셋을 그래프로 표현하기 - 데이터 시각화/차원 축소(Dimensionality reduction)
12. 구매 이력을 기반으로 상품 추천 - 추천 시스템/ANN
13. 지능형 게임 봇 - 강화학습



# 1.4 머신러닝 시스템의 종류

넓은 범주에서 분류하면 다음과 같다.

- 사람의 감독하에 훈련하는가?  - **지도학습 VS 비지도학습**
- 실시간으로 점진적인 학습을 하는가? -  **온라인 학습 VS 배치 학습**

- 예측 모델을 만드는가? 알고 있는 데이터 포인트와 비교하는가? - **모델 기반 학습 VS 사례 기반 학습 **

## 1.4.1 지도 학습과 비지도 학습

머신러닝 시스템을 **'학습하는 동안의 감독 형태나 정보량'**에 따라 분류할 수 있다. - **지도 학습, 비지도 학습. 준지도 학습, 강화 학습**

### 지도 학습(Supervised Learning)

- **지도 학습은** **훈련 데이터**에 **레이블**(Label)이 포함된다.

- **분류**(Classification)와 **회귀**(Regression)가 대표적인 지도 학습 작업이다.

- **회귀**는 **특성**(예측변수)를 사용해 **타겟**수치를 예측하는 것이다.

- 일부 **회귀** 알고리즘은 **분류**에 사용할 수도 있다. 또한 일부 **분류** 알고리즘도 **회귀**에 사용할 수도 있다.

- 다음은 가장 중요한 **지도 학습** 알고리즘이다.

  1. K-Nearest Neighbors (KNN, K-최근접 이웃)

  2. Linear Regression (선형 회귀)

  3. Logistic Regression (로지스틱 회귀)

  4. Support Vector Machine (SVM, 서포트 벡터 머신)

  5. Decision Tree ( 의사결정트리)

  6. Random Forest (랜덤 포레스트)

  7. Artificial Neural Networks (ANN or NN, 인공신경망)

### 비지도 학습(Unsupervised Learning)

- **비지도 학습**은 **훈련 데이터**에 **레이블**이 없다.
- 다음은 가장 중요한 **비지도 학습** 알고리즘이다.
  - 군집(Clustering)
    1. K-means (K-평균)
    2. DBSCAN (**D**ensity-**b**ased **s**patial **c**lustering of **a**pplications with **n**oise)
    3. HCA (계층 군집 분석, **H**ierarchical **C**luster **A**nalysis)
    4. Outlier Detection (이상치 탐지)
    5. Novelty Detection (특이치 탐지)
    6. One-class SVM (원-클래스)
    7. Isolation Forest (아이솔레이션 포레스트)
  - 시각화(Visualization)와 차원 축소(Dimensionally reduction)
    1. PCA (주성분 분석, **P**rincipal **C**omponent **A**nalysis)
    2. 커널(kernel) PCA
    3. LLE (지역적 선형 임베딩, Locally-Linear Embedding)
    4. t-SNE (**t**-**D**istrubuted **S**tochastic **N**eighbor **E**mbedding)
  - 연관 규칙 학습(Association rule learning)
    1. Apriori (어프라이어리)
    2. Eclat (이클렛)
- **HCA** 알고리즘을 이용하면 각 그룹을 더 작은 그룹으로 세분화할 수 있다.
- **시각화** 알고리즘은 대규모의 고차원 데이터를 도식화가 가능한 2D or 3D 표현으로 만들어준다.
- **시각화** 알고리즘은 가능한 한 구조를 그대로 유지하려 하므로 데이터가 어떻게 조직되어 있는지 이해할 수 있고 예상치 못한 패턴을 발견할 수 있다.
- **차원 축소**는  너무 많은 정보를 잃지 않으면서 데이터를 간소화하는 작업이다.
- **차원 축소**를 하는 한 가지 방법은 상관관계가 있는 여러 특성을 하나로 합치는 것이다. 이를 **특성 추출**(Feature Extraction)이라고 한다.
- **이상치 탐지**는 이상한 값을 자동으로 제거할 때 사용된다.
- **이상치 탐지** 알고리즘을 훈련할때는 대부분 정상적인 샘플이 필요하다.
- **특이치 탐지**는 훈련 세트의 모든 샘플과 달라 보이는 새로운 샘플을 탐지하는 것이 목적이다.
- **특이치 탐지** 알고리즘을 학습시키기 위해서는 매우 **"깨끗한"** 훈련 세트가 필요하다.
- **연관 규칙 학습**은 대량의 데이터에서 특성 간의 흥미로운 관계를 찾는 것이 목표이다.

### 준지도 학습 (Semisupervised Learning)

- **준지도 학습**은 일부만 레이블이 있는 데이터를 다룰 수 있다.
- 대부분의 **준지도 학습** 알고리즘은 **지도 학습**과 **비지도 학습**의 조합으로 이루어져 있다.
- 예시로, **DBN**(심층 신뢰 신경망, **D**eep **B**elief **N**etwork)은  **RBM**(제한된 볼츠만 머신, **R**estricted **B**oltzmann **M**achine)이라고 불리는 비지도 학습 알고리즘을 여러 겹 쌓은 것인데 **RBM**이 **비지도 학습**으로 순차적으로 훈련된 다음 전체 시스템이 **지도 학습** 방식으로 세밀하게 조정된다.

### 강화 학습 (Reinforcement Learning)

- **강화 학습**은 매우 다른 종류의 알고리즘이다.
- **강화 학습**은 다음과 같이 작동한다
  1. 학습하는 시스템인 **에이전트**(Agent)가 **환경**(Environment)를 관찰해서 **행동**(Action)을 실행한다.
  2. 그 결과로 **보상**(Reward) 또는 부정적 보상인 **벌점**(Penalty)를 받는다.
  3. 시간이 지나면서 가장 큰 **보상**을 얻기 위해 **정책**(Policy)라고 부르는 최상의 전략을 학습한다. 
  4. **정책**이란 주어진 **상황**에서 **에이전트**가 어떤 **행동**을 선택할지 정의한다.
- 강화학습의 대표적인 예는 보행로봇과 **DeepMind**의 **AlphaGo**이다.

## 1.4.2 배치 학습과 온라인 학습

머신러닝 시스템을 분류하는 데 사용하는 다른 기준은 **'입력 데이터의 스트림으로 부터 점진적으로 학습할 수 있는지 여부'**이다.

### 배치 학습(Batch Learning)

- **배치 학습**에서는 시스템이 점진적으로 학습할 수 없고, 사용할 수 있는 데이터를 모두 사용해 훈련시켜야 한다.
- 일반적으로 이 방식은 시간과 자원을 많이 소모하므로 보통 **오프라인 학습**에서 수행된다.
- 시스템을 훈련시킨 뒤 제품에 적용하면, 더 이상의 학습이 없이 이미 학습한 것을 적용만 한다. 따라서 새로운 데이터를 학습하기 위해서는 **이전 데이터를 포함한 전체 데이터**를 사용하여 처음부터 다시 훈련시켜야 한다. 인를 **오프라인 학습**(Offline Learning)이라고 한다.
- 변화에 적응하기 위해서 필요한 만큼 자주 훈련시키면 되는데, 보통 **24시간** 혹은 **매 주** 시스템을 훈련시킨다.
- 만약 **빠르게 변화하는** 데이터에 적응해야 한다면 더욱 **능동적인 방법**이 필요하다.
- 전체 데이터 세트를 활용하기 때문에 **대량의 데이터**를 새로 훈련시키는 데 많은 컴퓨팅 자원이 필요하고, 심한 경우 배치 학습을 **사용할 수 없다**.

### 온라인 학습 (Online Learning)

- 인터넷에 연결되어 학습한다는게 아니다.
- **온라인 학습**은 데이터를 순차적으로 **한 개씩** 또는 **미니 배치**(mini-batch)라 불리는 묶음 단위로 시스템을 훈련시킨다.
- 매 학습 단계가 빠르고 비용이 적어 데이터가 도착하는 대로 즉시 학습할 수 있다. 따라서, **연속적으로 데이터를 받고** **빠른 변화에 스스로 적응**해야하는 시스템이나 **컴퓨팅 자원이 제한된 경우**에 적합하다.
- 데이터를 재사용하기 위해 보관할 필요가 없다면, 학습이 끝난 데이터는 버려도 된다.즉, **많은 공간을 절약**할 수 있다.

- 메인 메모리에 들어갈 수 없을 정도로 큰 데이터 셋을 학습하는 데에도 온라인 학습을 이용할 수 있다. 이를 **외부 메모리 학습**(Out-of-core 학습)이라고 하며, 데이터의 일부를 읽어들이면서 전체 데이터가 모두 적용될 때까지 학습한다. (보통 오프라인 학습으로 한다. 점진적인 학습이라고 생각하면 편함)
- 온라인 학습에서 중요한 파라미터 하나는 **학습률**(Leaning rate)이다. 학습률을 높게하면 빠르게 적응하지만 이전 데이터를 빠르게 잊어버린다. 반대로 학습률이 낮으면 더욱 느리게 학습되겠지만 나쁜 데이터에 덜 민감해진다.
- 온라인 학습의 단점은 나쁜 데이터가 주입되면 서서히 성능이 저하된다는 것이다. 이를 방지하기 위해서 시스템을 면밀히 모니터링하고 성능이 저하되면 학습을 중단해야한다. **이상치 탐지 알고리즘**을 사용하여 비정상 데이터를 잡아낼 수 있다.

## 1.4.3 사례 기반 학습과 모델 기반 학습

머신러닝 시스템을 **"일반화 시키는 방법"**으로도 분류 할 수 있다.

대부분의 머신러닝 작업은 **예측**을 만드는 것이다. 즉, 훈련데이터로 학습하고 본적 없는 **새로운 데이터**에서 좋은 예측을 만들어야 한다는 뜻이다. 즉, 훈련데이터로 일반화를 해야한다. 훈련 데이터에서 높은 성능을 내는 것이 좋지만 진짜 목표는 **새로운 샘플에서 잘 작동하는** 모델이다.

### 사례 기반 학습 (Instance-based Learning)

- 단순히 기억하여 학습하는 간단한 형태이다.
- 훈련 샘플을 기억하고 유사도를 측정하여 새로운 데이터와 학습한 샘플 혹은 그 일부를 비교하는 식으로 일반화한다.

### 모델 기반 학습 (Model-based Learning)

- 샘플들의 모델을 만들어 예측에 사용한다.
- 데이터를 그래프로 나타내면 데이터가 흩어져 있어 어느정도 무작위성이 있지만 **경향성**을 나타낼 때가 있다.
- **모델 기반 학습** 과정에서는 어떠한 방법으로 모델링할지 고르는 **모델 선택**(Model Selection) 과정이 있다.
- **훈련된 최종 모델** 중 하나를 고르는 것도 **모델 선택**이라고 한다.
- **모델**은 **모델 파라미터**(Model Parameter)을 가진다. **학습**은 **모델 파라미터**를 올바르게 조정하는 것이다.
- **모델 파라미터**를 올바르게 조정하기 위해서는 **모델**이 얼마나 좋은지 측정하는 **효용 함수**(Utility Function) 또는 **적합도 함수**(Fitness Function)이라고 불리는 것이 필요하다. 또는 얼마나 나쁜지 측정하는 **비용 함수**(Cost Function)가 필요하다.
- 전형적인 머신러닝 프로젝트의 형태를 요약하면 다음과 같다.
  1. 데이터를 분석한다
  
  2. 모델을 선택한다
  
  3. 훈련 데이터로 모델을 훈련시킨다
  
  4. 새로운 데이터에 모델을 적용해 예측을 한다. (이를 **추론**(Inference) 라고 함)
  
     

# 1.5 머신러닝의 주요 도전 과제

우리의 주요 작업은 학습 알고리즘을 선택해서 어떤 데이터에 훈련시키는 것이므로 문제가 될 수 있는 것은 **나쁜 알고리즘**과 **나쁜 데이터**이다.

## 1.5.1 충분하지 않은 양의 훈련 데이터

- 대부분의 머선러닝 알고리즘이 잘 작동하려면 **데이터가 많아야 한다**. 아주 간단한 문제에서 조차도 수천 개의 데이터가 필요하다.
- 여러 머신러닝 알고리즘에 충분한 데이터가 주어지면 복잡한 자연어 중의성 해서 문제를 거의 비슷하게 잘 처리한다 (**Michele Banko**와 **Eric Brill**의 [논문](https://homl.info/6)) . 이 결과가 제시하는 것은 시간과 돈을 알고리즘 개발에 쓰는 것과 말뭉치(데이터) 개발에 쓰는 것 사이의 트레이드오프에 대해 생각해봐야 한다는 것이다.
- 즉, 아직 알고리즘을 무시해서는 안되지만, 복잡한 문제에서 알고리즘보다 데이터가 더 중요하다.

## 1.5.2 대표성이 없는 훈련 데이터

- 일반화가 잘 되기 위해서는 **일반화하기를 원하는 새로운 사례**를 훈련 데이터가 잘 대표하는 것이 중요하다. 하지만 그런 데이터를 사용하는 것이 어려울 때가 많다.
- 샘플이 작으면 우연성이 강하고 대표성이 없는 **샘플링 잡음**(Samplng Noise), 매우 큰 샘플에서는 추출 방법이 잘못되어 대표성이 없어지는 **샘플링 편향**(Sampling bias)가 생긴다.

## 1.5.3 낮은 품질의 데이터

- 훈련 데이터가 **에러**, **이상치**(Outlier), **잡음**으로 가득하면 머신러닝이 내재된 패턴을 찾기 어려워 잘 작동하지 않을 것이다. 그렇기 때문에 데이터 정제에 시간을 투차할 가치는 충분하다. 실제로도 많은 데이터 과학자가 데이터 정제에 많은 시간을 쓴다.
- 다음은 훈련 데이터 정제가 필요한 경우이다.
  1. 일부 샘플이 **이상치**라는 게 명확하다면 그것들을 무시하거나 수동으로 고치는 것이 좋다
  2. 일부 샘플에 특성 몇 개가 빠져있다면, 이 특성을 모두 무시할지, 이 샘플만 무시할지, 빠진 값을 채울지, 이 특성을 넣은 모델과 제외한 모델을 따로 훈련시킬 것인지 결정해야 한다.

## 1.5.4 관련 없는 특성

- 훈련 데이터에 관련 없는 특성이 적고 관련 있는 특성이 충분해야 시스템이 학습할 수 있다.
- 성공적인 머신러닝 프로젝트의 핵심 요소는 훈련에 사용할 좋은 특성들을 찾는 것이다. 이를 **특성 공학**(Feature Engineering)이라 하며 다음과 같은 작업이다.
  - 특성 선택 (Feature Selection) - 가지고 있는 특성 중에서 가장 유용한 특성을 선택한다
  - 특성 추출 (Feature Extraction) - 특성을 결합하여 더 유용한 특성을 만든다. **차원 축소 알고리즘**이 도움이 될 수 있다.
  - 새로운 데이터를 수집해 새 특성을 만든다.

## 1.5.5 훈련 데이터 과대적합

- 알고리즘이 과도하게 일반화를 하는 것을 **과대적합**(**Overfitting**)이라고 한다. **과대적합**이 일어났을 때는 모델이 **훈련 데이터에 너무 잘 맞지만 일반성이 떨어진다**.
- 훈련 세트에 **잡음이 많거나 데이터셋이 너무 작으면** **잡음이 생긴 패턴**을 감지하게 된다. 모델이 찾은 패턴이 이런 **잡음에 의한 것인지, 진짜인지** 모델이 구분해낼 방법은 **없다**.
- **과대적합**은 훈련 데이터의 잡음의 양에 비해 모델이 너무 복잡할 때 일어난다. 해결방법은 다음과 같다
  - 파라미터 수가 적은 모델을 선택하거나, 훈련 데이터에 있는 특성 수를 줄이거나, 모델에 제약을 가하여 **단순화 시킨다**.
  - 훈련 데이터를 **더 많이 모은다**.
  - 훈련 데이터의 **잡음을 줄인다.**
- 모델을 단순하게 하고 모델에 제약을 가하는 것을 **규제**(Regularization)이라고 한다.  **데이터에 완벽히 맞추는 것**과 **일반화를 위해 단순한 모델을 유지**하는 것 사이의 균형을 찾는 것이 좋다.
- **규제**의 양은 **하이퍼 파라미터**(Hyperparameter)가 결정한다. 하이퍼 파라미터는 알고리즘의 파라미터로 훈련동안 **상수로 남아있다**. **하이퍼파라미터 튜닝은 매우 중요한 과정이다.**

## 1.5.6 훈련 데이터 과소적합

- **과소적합**(Underfitting)은 **과대적합**의 반대로, 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못하는 것이다.
- 이 문제를 해결하는 주요 기법은 다음과 같다.
  - **모델 파라미터가 더 많은** 강력한 모델을 선택한다.
  - 학습 알고리즘에 **더 좋은 특성**을 제공한다 (특성 공학)
  - 모델의 **제약을 줄인다**.

## 1.5.7 한걸음 물러서서

큰 그림을 그려보면 다음과 같다

- 머신러닝은 명시적 규칙을 코딩하지 않고 기계가 데이터로부터 학습하여 어떤 작업을 더 잘하도록 만드는 것이다.
- 여러 종류의 머신러닝 시스템이 있다. **지도학습 vs 비지도학습**, **배치 학습 vs 온라인 학습**, **사례 기반 학습 vs 모델 기반 학습**
- 머신러닝 프로젝트에서는 훈련 데이터를 모아 학습 알고리즘에 주입한다. **모델 기반 학습**에서는 훈련 세트에 모델을 맞추기 위해 **모델 파라미터를 조정하고**, **사례 기반 학습**에서는 학습한 샘플과 새로운 샘플을 **비교**하여 일반화한다.
- **훈련세트가 너무 작거나**, **대표성이 없거나**, **잡음이 많고 관련없는 특성이 많다면** 시스템이 잘 작동하지 않는다.
- 모델이 너무 단순하거나(**과소적합**), 너무 복잡하지 않아야 한다(**과대적합**)



# 1.6 테스트와 검증



